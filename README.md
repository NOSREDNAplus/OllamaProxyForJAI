# OllamaProxyForJAI
A solution for self hosting LLMs using Ollama and using it as a proxy through Janitorai, re-routes traffic through local host to support generation. Supports text streaming 
